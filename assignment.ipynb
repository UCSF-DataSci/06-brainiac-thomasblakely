{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fa0ac4",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Network Showdown\n",
    "\n",
    "Build and compare neural network architectures on image and time-series data.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebeae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-metal (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-metal\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt\n",
    "\n",
    "# GPU acceleration (platform-specific)\n",
    "import platform\n",
    "if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "    %pip install -q tensorflow-metal\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed70f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected — using CPU\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     Dense, Flatten, Dropout, Conv2D, MaxPooling2D, LSTM, Input\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     load_cifar10, load_ecg5000,\n\u001b[32m     31\u001b[39m     plot_training_history, plot_confusion_matrix,\n\u001b[32m     32\u001b[39m     plot_sample_images, plot_ecg_traces, plot_predictions,\n\u001b[32m     33\u001b[39m     CIFAR10_CLASSES, ECG_CLASSES,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     36\u001b[39m OUTPUT_DIR = \u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/06-brainiac-thomasblakely/.venv/lib/python3.13/site-packages/sklearn/metrics/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Score functions, performance metrics, pairwise metrics and distance computations.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_classification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     accuracy_score,\n\u001b[32m      9\u001b[39m     balanced_accuracy_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     zero_one_loss,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dist_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/06-brainiac-thomasblakely/.venv/lib/python3.13/site-packages/sklearn/metrics/cluster/__init__.py:12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bicluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m consensus_score\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_supervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     adjusted_mutual_info_score,\n\u001b[32m     14\u001b[39m     adjusted_rand_score,\n\u001b[32m     15\u001b[39m     completeness_score,\n\u001b[32m     16\u001b[39m     contingency_matrix,\n\u001b[32m     17\u001b[39m     entropy,\n\u001b[32m     18\u001b[39m     expected_mutual_information,\n\u001b[32m     19\u001b[39m     fowlkes_mallows_score,\n\u001b[32m     20\u001b[39m     homogeneity_completeness_v_measure,\n\u001b[32m     21\u001b[39m     homogeneity_score,\n\u001b[32m     22\u001b[39m     mutual_info_score,\n\u001b[32m     23\u001b[39m     normalized_mutual_info_score,\n\u001b[32m     24\u001b[39m     pair_confusion_matrix,\n\u001b[32m     25\u001b[39m     rand_score,\n\u001b[32m     26\u001b[39m     v_measure_score,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unsupervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     calinski_harabasz_score,\n\u001b[32m     30\u001b[39m     davies_bouldin_score,\n\u001b[32m     31\u001b[39m     silhouette_samples,\n\u001b[32m     32\u001b[39m     silhouette_score,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m __all__ = [\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_mutual_info_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_rand_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mv_measure_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/06-brainiac-thomasblakely/.venv/lib/python3.13/site-packages/sklearn/metrics/cluster/_supervised.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse \u001b[38;5;28;01mas\u001b[39;00m sp\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_expected_mutual_info_fast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     expected_mutual_information,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     _max_precision_float_dtype,\n\u001b[32m     23\u001b[39m     get_namespace_and_device,\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Report available accelerators\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU acceleration: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU detected — using CPU\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Flatten, Dropout, Conv2D, MaxPooling2D, LSTM, Input\n",
    ")\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from helpers import (\n",
    "    load_cifar10, load_ecg5000,\n",
    "    plot_training_history, plot_confusion_matrix,\n",
    "    plot_sample_images, plot_ecg_traces, plot_predictions,\n",
    "    CIFAR10_CLASSES, ECG_CLASSES,\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f79d00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Dense Baseline on CIFAR-10\n",
    "\n",
    "**Task:** Build a Dense (fully connected) network to classify CIFAR-10 images.\n",
    "\n",
    "CIFAR-10 has 60,000 color images (32x32x3) across 10 classes. A Dense network\n",
    "flattens each image into 3,072 numbers and classifies from there. This is our\n",
    "baseline — it ignores spatial structure entirely.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- Flatten the input\n",
    "- At least 2 hidden Dense layers with ReLU activation\n",
    "- Dropout after each hidden layer\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Part 1: Dense Baseline on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load data (normalized to [0,1], one-hot encoded)\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training images to verify data loaded correctly\n",
    "plot_sample_images(X_train, y_train, CIFAR10_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dense model using Sequential\n",
    "model_dense = Sequential([\n",
    "    Input(shape=(32, 32, 3)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52067ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_dense.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 5, # Stop 5 epochs no improvement\n",
    "    restore_best_weights = True # Roll back to best epoch weight\n",
    "    )\n",
    "\n",
    "history_dense = model_dense.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20, batch_size = 64,\n",
    "    validation_split = 0.1,\n",
    "    callbacks = [early_stop]\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model_dense.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "# Generate predictions and confusion matrix\n",
    "y_pred = np.argmax(model_dense.predict(X_test, verbose = 0), axis = 1)  \n",
    "y_true = np.argmax(y_test, axis = 1)  \n",
    "cm = confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6de654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "plot_predictions(X_test, y_true, y_pred, CIFAR10_CLASSES)\n",
    "plot_confusion_matrix(y_true, y_pred, list(CIFAR10_CLASSES.values()),\n",
    "                      os.path.join(OUTPUT_DIR, \"part1_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results = {\n",
    "    \"accuracy\": float(test_acc),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part1_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(f\"Dense loss: {test_loss:.4f}\")\n",
    "print(\"Saved output/part1_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4daa2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CNN on CIFAR-10\n",
    "\n",
    "**Task:** Build a CNN to classify the same CIFAR-10 images. Compare its accuracy\n",
    "to the Dense baseline from Part 1.\n",
    "\n",
    "CNNs use convolutional filters that slide across the image, detecting local\n",
    "patterns (edges, textures, shapes). This preserves spatial structure that\n",
    "Dense layers discard.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- At least 2 Conv2D + MaxPooling2D blocks\n",
    "- Flatten, then Dense hidden layer with Dropout\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a124f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 2: CNN on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Data is already loaded from Part 1 (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a CNN model using Sequential\n",
    "model_cnn = Sequential([\n",
    "    Input(shape = (32, 32, 3)),\n",
    "    Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation = 'softmax')\n",
    "]) \n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_cnn.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with EarlyStopping and ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss', patience=3,\n",
    "        restore_best_weights = True),\n",
    "    ModelCheckpoint(\n",
    "        'output/best_cnn.keras',\n",
    "        save_best_only=True, monitor='val_accuracy'),\n",
    "]\n",
    "\n",
    "history_cnn = model_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 15, batch_size = 64,\n",
    "    validation_split = 0.1,callbacks = callbacks\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd07834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    history_cnn,\n",
    "    os.path.join(OUTPUT_DIR, \"part2_training_history.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "cnn_loss, cnn_acc = model_cnn.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "# Generate predictions and confusion matrix\n",
    "y_pred_cnn = np.argmax(model_cnn.predict(X_test, verbose = 0), axis = 1)\n",
    "y_true_cnn = np.argmax(y_test, axis = 1)\n",
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d455628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "plot_predictions(X_test, y_true_cnn, y_pred_cnn, CIFAR10_CLASSES)\n",
    "plot_confusion_matrix(\n",
    "    y_true_cnn, y_pred_cnn, list(CIFAR10_CLASSES.values()),\n",
    "    os.path.join(OUTPUT_DIR, \"part2_confusion_matrix.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_cnn = {\n",
    "    \"accuracy\": float(cnn_acc),\n",
    "    \"confusion_matrix\": cm_cnn.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part2_results.json\"), \"w\") as f:\n",
    "    json.dump(results_cnn, f, indent=2)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\"model\": \"Dense\", \"accuracy\": float(test_acc)},\n",
    "    {\"model\": \"CNN\", \"accuracy\": float(cnn_acc)},\n",
    "])\n",
    "comparison.to_csv(os.path.join(OUTPUT_DIR, \"part2_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"CNN accuracy:   {cnn_acc:.4f}\")\n",
    "print(f\"CNN loss:       {cnn_loss:.4f}\")\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(f\"Improvement:    {cnn_acc - test_acc:+.4f}\")\n",
    "print(\"Saved output/part2_results.json and output/part2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f949ce7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: LSTM on ECG5000\n",
    "\n",
    "**Task:** Build an LSTM to classify heartbeat recordings.\n",
    "\n",
    "ECG5000 contains 5,000 heartbeat recordings — each is 140 time steps of voltage\n",
    "measurements, classified into 5 types (Normal, Supraventricular, Premature\n",
    "Ventricular, Fusion, Unknown). This is sequential data where order matters,\n",
    "making it a natural fit for recurrent networks.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- LSTM layer (any reasonable number of units)\n",
    "- Dropout for regularization\n",
    "- Dense output with softmax (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 3: LSTM on ECG5000\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load ECG data (already shaped for RNN input)\n",
    "X_train_ecg, y_train_ecg, X_test_ecg, y_test_ecg = load_ecg5000()\n",
    "print(f\"Train: {X_train_ecg.shape}, Test: {X_test_ecg.shape}\")\n",
    "print(f\"Classes: {list(ECG_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ECG traces to understand the data\n",
    "plot_ecg_traces(X_train_ecg, y_train_ecg, ECG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an LSTM model using Sequential\n",
    "model_lstm = Sequential([\n",
    "    Input(shape = (140, 1)),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation = 'softmax')\n",
    "]) \n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_lstm.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    "    )\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train_ecg, y_train_ecg,\n",
    "    epochs = 45, batch_size = 128,\n",
    "    validation_split = 0.1,\n",
    "    callbacks = [early_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    history_lstm,\n",
    "    os.path.join(OUTPUT_DIR, \"part3_training_history.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b28180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "lstm_loss, lstm_acc = model_lstm.evaluate(X_test_ecg, y_test_ecg, verbose = 0)\n",
    "\n",
    "# Generate predictions and confusion matrix\n",
    "y_pred_ecg = np.argmax(model_lstm.predict(X_test_ecg, verbose = 0), axis = 1)\n",
    "y_true_ecg = np.argmax(y_test_ecg, axis = 1)\n",
    "cm_ecg = confusion_matrix(y_true_ecg, y_pred_ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize confusion matrix to see which heartbeat types are confused\n",
    "plot_confusion_matrix(\n",
    "    y_true_ecg, y_pred_ecg, list(ECG_CLASSES.values()),\n",
    "    os.path.join(OUTPUT_DIR, \"part3_confusion_matrix.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_ecg = {\n",
    "    \"accuracy\": float(lstm_acc),\n",
    "    \"confusion_matrix\": cm_ecg.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part3_results.json\"), \"w\") as f:\n",
    "    json.dump(results_ecg, f, indent=2)\n",
    "\n",
    "print(f\"LSTM accuracy: {lstm_acc:.4f}\")\n",
    "print(f\"LSTM loss: {lstm_loss:.4f}\")\n",
    "print(\"Saved output/part3_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69849039",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00802a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAll parts complete!\")\n",
    "print(\"Run 'pytest .github/tests/ -v' in your terminal to check your work.\")\n",
    "print(\"TEST RESULTS PASSED! UPLOADIN TO GITHUB!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
